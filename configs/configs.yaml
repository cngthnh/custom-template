settings:
  #################   DATASET CONFIG   ###################

  project_name: "coco2017"    # also the folder name of the dataset that under ./data folder
  train_imgs: images/train2017
  val_imgs: images/val2017
  test_imgs: 
  train_anns: annotations/instances_train2017.json    # class index must start from 1
  val_anns: annotations/instances_val2017.json        # class index must start from 1

  #################   TRAINING CONFIG   ###################
  
  model_name: 'yolov5m' #[efficientdet-d{i} (0-7) | fasterrcnn-{backbone} | yolov4-p{i} (5,7) | yolov5{i} (s,m,l,x)]

  #pretrained_backbone: './weights/pretrained/pretrained_fold0_d4.pth'                  # Pretrained backbone, uncomment to use
  
  gpu_devices: '0'                     # supports multi-gpus
  num_epochs: 100
  batch_size: 16
  num_workers: 2

  fusion_mode: 'nms'                    # Post-process method [nms | wbf | None]
  min_iou_val:  0.5                     # IOU threshold for validation
  min_conf_val: 0.01                    # Confidence score threshold for validation
  max_images_val: 10000                 # max number of images for validation
  max_pre_nms: 30000                     # max detections for post process, input to NMS, set <0 for default [effdet: 5000; frcnn: 1000; yolo: 30000]
  max_post_nms: 300                     # max detections per image limit, output of NMS, set <0 for default [effdet: 100; frcnn: 100; yolo: 300]

  image_size: [1024,1024]               # should be square to prevent bugs [512, 640, 768, 896, 1024, 1280, 1280, 1536, 1536]
  keep_ratio: True                     # whether to use resize padding

  cutmix: True
  mixup: True
  progressive_steps: [5, 10, 15]        # progressive learning with 2 levels (fixed), level up when reach at each number of epoch
                                        # leave blank list to disable, ONLY WORKS WITH YOLOv5
  # learning rate policy
  lr_policy:
    name: "adam"                         #[adam|sgd]
    lr: 0.001                            #[adam: 1e-3 | sgd: 1e-2]
    momentum: 0.937
    weight_decay: 0.0005

  lr_scheduler:
    name: "cosine"                      #[plateau | cosine | 1cycle-yolo | 1cycle]
                                        # if need to specify more scheduler arguments, do it here

  # gradient accumulation
  mixed_precision: True                # whether to use nvidia apex
  total_accumulate_steps: 64          # step * batch_size, not use if equal 0

  # Test time augmentation
  tta: False                             # whether to use TTA while validation
  tta_ensemble_mode: "wbf"              # ensemble method when TTA
  tta_conf_threshold: 0.01
  tta_iou_threshold: 0.9